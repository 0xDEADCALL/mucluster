# Use YARN for resource management
spark-master                    yarn

# Run in "cluster" --> Driver will be spawned in one of the worker nodes (master)
# The client won't need to be "alive"
spark.submit.deployMode         client

# Executors and drivers memory
spark.driver.memory             512m
spark.executor.memory           512m

# Memory to be used for YARN Application Master (client)
spark.yarn.am.memory            1G

# Enable event logging
spark.eventLog.enabled           true
spark.eventLog.compress          false
spark.eventLog.dir               hdfs://node-master:11000/spark-logs
spark.history.fs.logDirectory    hdfs://node-master:11000/spark-logs
# spark.eventLog.dir               s3a://spark-logs/logs/
# spark.history.fs.logDirectory    s3a://spark-logs/logs/
spark.yarn.historyServer.address localhost:18080
spark.history.fs.update.interval 10s
spark.history.ui.port            18080
spark.io.compression.codec       snappy



# Configure MinIO
spark.jars.packages                                 org.apache.hadoop:hadoop-aws:3.3.4,io.delta:delta-spark_2.12:3.0.0
spark.sql.extensions                                io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog                     org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.hadoop.fs.s3a.endpoint                        http://minio:10000
spark.hadoop.fs.s3a.access.key                      y9kmpQA4RC2asIF4toWi
spark.hadoop.fs.s3a.secret.key                      M9piklUa69UTjMcnX4zW1hl7LJJHym7BLbm0GZ2C
spark.hadoop.fs.s3a.path.style.access               true
spark.hadoop.fs.s3a.connection.ssl.enabled          false
spark.hadoop.fs.s3a.impl                            org.apache.hadoop.fs.s3a.S3AFileSystem
spark.yarn.historyServer.address	                spark-history-server:18080
spark.driver.defaultJavaOptions                     -XX:+IgnoreUnrecognizedVMOptions  --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/jdk.internal.misc=ALL-UNNAMED
spark.executor.defaultJavaOptions                   -XX:+IgnoreUnrecognizedVMOptions  --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/jdk.internal.misc=ALL-UNNAMED
